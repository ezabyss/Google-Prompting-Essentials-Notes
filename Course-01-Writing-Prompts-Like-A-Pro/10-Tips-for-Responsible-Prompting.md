# Tips for Responsible Prompting

*Notes by Abhishek (Ez Abyss)*

---

## ðŸŒŸ Big Idea

Generative AI tools are excellent at **processing information and recognizing patterns**, but they **lack critical thinking and human awareness**.

Thatâ€™s why learning to **prompt responsibly** is essential â€” especially in realâ€‘world and workplace use.

---

## âš ï¸ Ethical Risks & AI Limitations

Gen AI tools are not perfect. Their outputs may include:

* Mistakes or inaccuracies
* Bias and stereotypes
* Misleading or harmful information

âž¡ï¸ This is why a **humanâ€‘inâ€‘theâ€‘loop** approach is critical.

> A human must **verify AI outputs** before using them.

---

## ðŸ§  Biases & Stereotypes

AI can unintentionally reproduce existing biases (age, gender, race, culture).

### How to reduce bias in outputs

#### 1ï¸âƒ£ Specify diversity

Use inclusive and descriptive language in your prompts.

âŒ â€œA table of delicious foodsâ€
âœ… â€œA table of delicious foods from all over the worldâ€

This gives you more control and leads to better results.

---

#### 2ï¸âƒ£ Challenge assumptions

If the AI output shows bias:

* Point it out explicitly
* Ask the tool to correct it

**Example:**
If food images mostly represent one region, iterate and ask for:

* Foods from West Africa
* Foods from Northern Europe

Providing feedback helps reduce bias and improve future outputs.

---

## ðŸŒ€ Hallucinations

A **hallucination** occurs when AI produces false or incorrect information.

Hallucinations may happen when:

* Prompts are vague or unclear
* The AI guesses about topics it wasnâ€™t trained well on

Examples:

* Incorrect math calculations
* Wrong ingredients in a recipe
* False historical or factual claims

---

### How to navigate hallucinations

#### âœ”ï¸ Factâ€‘check and crossâ€‘reference

* Use search engines
* Check multiple sources
* Consult experts if available
* Compare outputs from more than one tool

---

#### âœ”ï¸ Use clearer and more detailed language

AI may treat incorrect input as true.

âŒ â€œWhy is Toronto the capital of Canada?â€
âž¡ï¸ The AI may invent a false explanation.

Be precise and verify assumptions in your prompts.

---

## â“ Inconsistencies & Relevance Issues

AI may misunderstand:

* Idioms
* Figurative language
* Context

**Example:**
â€œThink outside the boxâ€ may be interpreted literally.

---

### How to fix relevance issues

#### âœ”ï¸ Provide references

Use representative references to guide the output.

#### âœ”ï¸ Add or refine context

Rephrase unclear language.

âŒ â€œThink outside the boxâ€
âœ… â€œConsider unique, unconventional approachesâ€

---

## ðŸ¢ Responsible Prompting at Work

Before using AI for work tasks, ask:

* Does this align with my responsibilities?
* Does it follow company AI policies?
* Am I risking sensitive or confidential data?
* Is this a public or private (enterprise) AI tool?

Always prioritize **human oversight**.

---

## âœ… Checklist: Using Gen AI Responsibly at Work

Before using AI:

* Decide if AI is appropriate for the task
* Consider whether it could reinforce harmful bias
* Get approval when required
* Evaluate privacy and security risks
* Use enterprise tools if available

After using AI:

* Review all outputs carefully
* Disclose AI use to teammates or clients
* Be transparent about how AI was used

---

## ðŸ§¹ When in Doubt, Clear the Memory

Clearing AI memory can improve output quality.

### Benefits of clearing memory

* Protects privacy
* Reduces bias carryover
* Prevents confusion
* Helps troubleshoot stuck outputs

âš ï¸ Note:
Some tools autoâ€‘clear memory, others require manual settings changes.

---

## ðŸ§  Final Takeaway

AI is a powerful tool â€” but **power requires responsibility**.

Best results come from:

* Human judgment
* Ethical awareness
* Clear, thoughtful prompts
* Continuous evaluation and iteration

> Use AI to assist your thinking â€” **not replace it**.

---
